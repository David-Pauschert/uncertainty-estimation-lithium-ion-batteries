{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from itertools import product\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_vector = pd.read_csv('../data/data_input_vector.csv')\n",
    "input_scalar = pd.read_csv('../data/data_input_scalar.csv')\n",
    "input_general = pd.read_csv('../data/data_input_general_Info.csv')\n",
    "output = pd.read_csv('../data/data_output.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Preparation of data_input_general.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATA PREPARATION\n",
    "\n",
    "# Drop unneeded columns\n",
    "input_general = input_general.drop(columns=[\"VAN\", \"Index\", \"absolute_timestamp\", 'stat_zeitpunkt_test'], axis=1)\n",
    "\n",
    "# Replace 'BMW' with 'D'\n",
    "input_general['fzg_verkaufsland_kfzint_kez'] = input_general['fzg_verkaufsland_kfzint_kez'].replace('BMW', 'D')\n",
    "\n",
    "# Convert dates to timestamps\n",
    "input_general['fzg_produktionsdatum'] = pd.to_datetime(input_general['fzg_produktionsdatum']).astype('int64')\n",
    "\n",
    "# OMIT OUTLIER HANDLING\n",
    "\n",
    "# PREPROCESSING\n",
    "numerical_features = input_general.select_dtypes(include=['int64', 'float64']).columns\n",
    "categorical_features = input_general.select_dtypes(include=['object']).columns\n",
    "\n",
    "numerical_transformer = Pipeline(steps=[('scaler', MinMaxScaler())])\n",
    "categorical_transformer = Pipeline(steps=[('onehot', OneHotEncoder(handle_unknown='ignore'))])\n",
    "\n",
    "preprocessor = ColumnTransformer(transformers=[\n",
    "    ('num', numerical_transformer, numerical_features),\n",
    "    ('cat', categorical_transformer, categorical_features)\n",
    "])\n",
    "\n",
    "X_general = preprocessor.fit_transform(input_general)\n",
    "X_general = X_general.toarray()  # Convert sparse matrix to dense matrix\n",
    "\n",
    "with open('../data/weekly_resampling/X_general.pkl', 'wb') as f:\n",
    "    pickle.dump(X_general, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "SPECIAL_VALUE = -1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Preparation of data_input_scalar.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows before outlier removal: 167820\n",
      "Rows after outlier removal: 154812\n"
     ]
    }
   ],
   "source": [
    "# DATA PREPARATION\n",
    "\n",
    "# Drop unneeded columns\n",
    "input_scalar = input_scalar.drop(columns=[\"Unnamed: 0\", \"absolute_timestamp\"], axis=1)\n",
    "\n",
    "# Drop rows with NaN values\n",
    "input_scalar = input_scalar.dropna()\n",
    "\n",
    "# Set auslesedatum relative to fzg_produktionsdatum (TODO check compatibility with resampling)\n",
    "#input_scalar['auslesedatum'] = pd.to_datetime(input_scalar['auslesedatum']).astype('int64')\n",
    "#fzg_produktionsdatum_dict = input_general.set_index('VAN')['fzg_produktionsdatum'].to_dict()\n",
    "#input_scalar['auslesedatum'] = input_scalar.apply(lambda row: row['auslesedatum'] - fzg_produktionsdatum_dict[row['VAN']], axis=1)\n",
    "\n",
    "# OUTLIER HANDLING\n",
    "\n",
    "class OutlierRemover(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, threshold=1.96):\n",
    "        self.threshold = threshold\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        X_num = X.drop(columns=['auslesedatum'], axis=1).select_dtypes(include=['int64', 'float64'])\n",
    "        z_scores = np.abs((X_num - X_num.mean()) / X_num.std())\n",
    "        mask = (z_scores < self.threshold).all(axis=1)\n",
    "        \n",
    "        # Debug: Print the number of rows before and after outlier removal\n",
    "        print(\"Rows before outlier removal:\", X.shape[0])\n",
    "        print(\"Rows after outlier removal:\", X[mask].shape[0])\n",
    "        \n",
    "        return X[mask]\n",
    "    \n",
    "outlier_remover = OutlierRemover(threshold=1.96)\n",
    "input_scalar = outlier_remover.fit_transform(input_scalar)\n",
    "\n",
    "# RESAMPLING\n",
    "\n",
    "# Convert dates to datetime\n",
    "input_scalar['auslesedatum'] = pd.to_datetime(input_scalar['auslesedatum'])\n",
    "\n",
    "# Sort values - this step is crucial for resampling\n",
    "input_scalar = input_scalar.sort_values(by=['VAN', 'auslesedatum'])\n",
    "\n",
    "# Group by 'VAN' and apply the resampling function\n",
    "input_scalar = input_scalar.groupby('VAN').resample('W', on='auslesedatum').mean().reset_index()\n",
    "input_scalar = input_scalar.dropna()\n",
    "\n",
    "# Convert dates to timestamps\n",
    "input_scalar['auslesedatum'] = pd.to_datetime(input_scalar['auslesedatum']).astype('int64')\n",
    "\n",
    "# PREPROCESSING\n",
    "\n",
    "numerical_features = input_scalar.select_dtypes(include=['int64', 'float64']).columns\n",
    "\n",
    "# Sort by VAN and auslesedatum\n",
    "input_scalar = input_scalar.sort_values(by=['VAN', 'auslesedatum'])\n",
    "\n",
    "# Create 3D array with shape (num_vehicles, max_seq_len, dimension)\n",
    "num_vehicles = output['VAN'].nunique()\n",
    "max_seq_len_scalar = input_scalar.groupby('VAN').size().max()\n",
    "dimension_scalar = len(numerical_features)\n",
    "X_scalar = np.full((num_vehicles, max_seq_len_scalar, dimension_scalar), fill_value=SPECIAL_VALUE, dtype=np.float64)\n",
    "\n",
    "# Scaling + Encoding\n",
    "scaler = MinMaxScaler()\n",
    "input_scalar[numerical_features] = scaler.fit_transform(input_scalar[numerical_features])\n",
    "\n",
    "for van in input_scalar['VAN'].unique():\n",
    "    van_data = input_scalar[input_scalar['VAN'] == van]\n",
    "    input_sequence = van_data.drop(columns=['VAN']).values\n",
    "    index = output.index[output['VAN'] == van].to_list()[0]\n",
    "    seq_len = input_sequence.shape[0]\n",
    "    X_scalar[index, 0:seq_len, :] = input_sequence\n",
    "    \n",
    "with open('../data/weekly_resampling/X_scalar.pkl', 'wb') as f:\n",
    "    pickle.dump(X_scalar, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Preparation of data_input_vector.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows before outlier removal: 95274\n",
      "Rows after outlier removal: 74184\n"
     ]
    }
   ],
   "source": [
    "# Drop unneeded columns\n",
    "exclude_columns = [\"Unnamed: 0\", \"absolute_timestamp\", \"BAUREIHE\", \n",
    "                    \"stat_zeit_temp_total_12_wert\", \"stat_zeit_temp_total_13_wert\", \n",
    "                    \"stat_zeit_temp_total_14_wert\", \"stat_hv_spannung_wert\"]\n",
    "input_vector = input_vector.drop(columns=exclude_columns, axis=1)\n",
    "\n",
    "# Drop rows with NAN values\n",
    "input_vector = input_vector.dropna()\n",
    "\n",
    "# Convert dates to timestamps\n",
    "input_vector['fzg_produktionsdatum'] = pd.to_datetime(input_vector['fzg_produktionsdatum']).astype('int64')\n",
    "\n",
    "# Set auslesedatum relative to fzg_produktionsdatum (TODO check compatibility with resampling)\n",
    "#input_vector['auslesedatum'] = pd.to_datetime(input_vector['auslesedatum']).astype(int)\n",
    "#input_vector['auslesedatum'] = input_vector['auslesedatum'] - input_vector['fzg_produktionsdatum']\n",
    "\n",
    "# OUTLIER HANDLING\n",
    "\n",
    "class IQRBasedOutlierRemover(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, factor=1.5):\n",
    "        self.factor = factor\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        X_num = X.drop(columns=['auslesedatum'], axis=1).select_dtypes(include=['int64', 'float64'])\n",
    "        Q1 = X_num.quantile(0.25)\n",
    "        Q3 = X_num.quantile(0.75)\n",
    "        IQR = Q3 - Q1\n",
    "        mask = ~((X_num < (Q1 - self.factor * IQR)) | (X_num > (Q3 + self.factor * IQR))).any(axis=1)\n",
    "        \n",
    "        # Debug: Print the number of rows before and after outlier removal\n",
    "        print(\"Rows before outlier removal:\", X.shape[0])\n",
    "        print(\"Rows after outlier removal:\", X[mask].shape[0])\n",
    "        \n",
    "        return X[mask]\n",
    "\n",
    "outlier_remover = IQRBasedOutlierRemover(factor=20)\n",
    "input_vector = outlier_remover.fit_transform(input_vector)\n",
    "\n",
    "# RESAMPLING\n",
    "\n",
    "# Convert dates to datetime\n",
    "input_vector['auslesedatum'] = pd.to_datetime(input_vector['auslesedatum'])\n",
    "\n",
    "# Sort values - this step is crucial for resampling\n",
    "input_vector = input_vector.sort_values(by=['VAN', 'auslesedatum'])\n",
    "\n",
    "# Group by 'VAN' and apply the resampling function\n",
    "input_vector = input_vector.groupby('VAN').resample('W', on='auslesedatum').mean().reset_index()\n",
    "input_vector = input_vector.dropna()\n",
    "\n",
    "# Convert dates to timestamps\n",
    "input_vector['auslesedatum'] = pd.to_datetime(input_vector['auslesedatum']).astype('int64')\n",
    "\n",
    "# PREPROCESSING\n",
    "\n",
    "numerical_features = input_vector.select_dtypes(include=['int64', 'float64']).columns\n",
    "\n",
    "# Sort by VAN and auslesedatum\n",
    "input_vector = input_vector.sort_values(by=['VAN', 'auslesedatum'])\n",
    "\n",
    "# Create 3D array with shape (num_vehicles, max_seq_len, dimension)\n",
    "num_vehicles = output['VAN'].nunique()\n",
    "max_seq_len_vector = input_vector.groupby('VAN').size().max()\n",
    "dimension_vector = len(numerical_features)\n",
    "X_vector = np.full((num_vehicles, max_seq_len_vector, dimension_vector), fill_value=SPECIAL_VALUE, dtype=np.float64)\n",
    "\n",
    "# Scaling + Encoding\n",
    "scaler = MinMaxScaler()\n",
    "input_vector[numerical_features] = scaler.fit_transform(input_vector[numerical_features])\n",
    "\n",
    "for van in input_vector['VAN'].unique():\n",
    "    van_data = input_vector[input_vector['VAN'] == van]\n",
    "    input_sequence = van_data.drop(columns=['VAN']).values\n",
    "    index = output.index[output['VAN'] == van].to_list()[0]\n",
    "    seq_len = input_sequence.shape[0]\n",
    "    X_vector[index, 0:seq_len, :] = input_sequence\n",
    "    \n",
    "with open('../data/weekly_resampling/X_vector.pkl', 'wb') as f:\n",
    "    pickle.dump(X_vector, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
